# Marlan - The Photo Profit Bot

An AI-powered chat application designed specifically for marketing assistance to portrait photographers. Marlan leverages GPT-4o models via the Vercel AI SDK, enhanced with retrieval-augmented generation (RAG), web scraping capabilities, and deep web search functionality through the Perplexity API.

## System Architecture Overview

Marlan is built as a modern Next.js 15 application with a focus on serverless architecture, vector-based knowledge retrieval, and specialized AI agents. The system is designed to provide photographers with targeted marketing advice by combining multiple knowledge sources:

1. **Vector Database (RAG)**: Pre-indexed photography marketing knowledge, stored in Supabase with pgvector
2. **Web Scraping**: Dynamic content extraction from URLs shared during conversations
3. **Deep Search**: Advanced web research capabilities via Perplexity API integration
4. **Custom Agents**: Specialized AI agents for different marketing domains (copywriting, Google Ads, etc.)

### Core Architecture Components

```
├── app/                    # Next.js app router pages
│   ├── api/                # API routes (serverless functions)
│   │   ├── auth/           # Authentication endpoints
│   │   ├── chat/           # Chat API endpoints
│   │   ├── widget-chat/    # Widget-specific chat endpoint
│   ├── chat/               # Chat interface pages
│   ├── admin/              # Admin dashboard pages
│   └── widget.js/          # Widget JavaScript loader
├── components/             # React components
│   ├── chat-widget/        # Embeddable widget components
│   ├── admin/widget/       # Widget configuration UI
├── lib/                    # Core business logic
│   ├── agents/             # AI agent implementation
│   │   ├── core/           # Base agent functionality
│   │   ├── prompts/        # Agent-specific prompts
│   │   ├── specialized/    # Specialized agent implementations
│   │   └── tools/          # Agent tool implementations
│   ├── vector/             # Vector search functionality
│   ├── chat/               # Chat processing logic
│   ├── logger/             # Structured logging system
│   └── widget/             # Widget backend functionality
├── public/                 # Static assets
│   └── widget/             # Compiled widget scripts
```

## Feature Implementation Details

### 1. Agent System

The agent system uses a sophisticated routing mechanism that analyzes user queries and directs them to specialized agents based on keyword matching and context analysis.

#### Agent Router (`lib/agents/agent-router.ts`)

- **Keyword-Based Routing**: Analyzes messages using weighted keyword dictionaries
- **Scoring Algorithm**: Multi-word keywords get higher scores (2 points per word)
- **Position Bonus**: Keywords at the beginning of messages receive a +5 score bonus
- **Exact Match Bonus**: Exact phrase matches receive a +3 score bonus
- **Threshold-Based Assignment**: Only routes to specialized agents when score exceeds 5 points

#### Agent Types

1. **Default Agent**: General marketing assistant
2. **Copywriting Agent**: Specialized for website copy, landing pages, email copy
3. **Google Ads Agent**: Optimized for search campaign creation and optimization
4. **Facebook Ads Agent**: Focused on social media advertising strategies
5. **Quiz Agent**: Designed for interactive content creation

#### Agent Base Implementation (`lib/agents/core/agent-base.ts`)

- Abstract base class providing core functionality for all agents
- Unified message handling and response generation
- Built-in tool execution framework
- Context management for stateful conversations
- Error handling and recovery mechanisms

### 2. Retrieval Augmented Generation (RAG)

The RAG system combines vector similarity search with optimized caching and performance monitoring.

#### Document Retrieval (`lib/vector/documentRetrieval.ts`)

- **Similarity Search**: Uses pgvector for cosine similarity search
- **Performance Monitoring**: Tracks and logs slow queries (>500ms)
- **Metrics Collection**: Records count, similarity scores, and retrieval time
- **Two-Tier Caching**: Implements Redis-based caching with two strategies:
  - **Exact Match**: Direct key lookup for identical queries
  - **Semantic Similarity**: Finds conceptually similar previously cached queries

#### Embedding Generation (`lib/vector/embeddings.ts`)

- Uses OpenAI's text-embedding-3-small model for vector generation
- LRU caching for frequently used embeddings to reduce API costs
- Batched embedding generation for efficiency
- Automatic retry with exponential backoff for reliability

#### Document Formatting (`lib/vector/formatters.ts`)

- Processes raw documents for optimal context inclusion
- Handles markdown, HTML, and plain text formatting
- Implements length-aware truncation to maximize token efficiency
- Prioritizes critical sections like headers and metadata

### 3. Web Scraping System

A comprehensive web content extraction system is implemented to enable URL-based knowledge retrieval.

#### Web Scraper Tool (`lib/agents/tools/web-scraper-tool.ts`)

- Automatic URL detection in messages
- HTML parsing with content extraction
- Handles JavaScript-heavy websites
- Content summarization for long pages
- Metadata extraction (OpenGraph, title, description)
- Error handling for unreachable or invalid URLs

#### Website Summarizer (`lib/agents/tools/website-summarizer.ts`)

- Deep crawling of entire websites
- Topical categorization of content
- Extraction of business information
- AI-powered summarization of key content
- Photography specialization detection

### 4. Perplexity Deep Search

Integration with Perplexity API for enhanced web research capabilities.

#### Deep Search Tool (`lib/agents/tools/perplexity/deep-search.ts`)

- Real-time web search via Perplexity Sonar/Sonar-Pro models
- Progress tracking with Server-Sent Events
- Concurrent search requests with result consolidation
- Source attribution for credibility
- Cache layer for frequently searched topics

#### Events Manager (`lib/api/events-manager.ts`)

- Server-Sent Events for real-time progress updates
- Event stream management with client reconnection handling
- Progress tracking for long-running operations
- Error notification system

### 5. Chat Functionality

The chat system implements a sophisticated processing pipeline for handling user messages.

#### Prompt Builder (`lib/chat/prompt-builder.ts`)

- Dynamic system prompt generation based on user profile and agent type
- Context-aware prompt construction
- Token optimization to maximize context window usage
- Profile information integration for personalized responses
- Multi-stage prompt assembly for complex queries

#### Stream Processor (`lib/chat/stream-processor.ts`)

- Handles real-time streaming of AI responses
- Implements chunked response handling
- Tool calling integration during streaming
- Error recovery for interrupted streams
- Format normalization across different AI providers

#### Tool Manager (`lib/chat/tool-manager.ts`)

- Dynamic tool registration based on user permissions
- Tool execution orchestration
- Result processing and integration into responses
- Error handling for tool execution failures
- Context window management for tool inputs/outputs

### 6. Chat Widget Implementation

A fully embeddable chat widget for external websites, with customizable appearance and behavior.

#### Widget Component (`components/chat-widget/chat-widget.tsx`)

- Self-contained React component with minimal dependencies
- Responsive design that adapts to mobile and desktop
- Customizable appearance (position, colors, title)
- Message history with session persistence
- Error handling and retry mechanisms
- Rate limiting feedback for users

#### Widget Configuration (`components/admin/widget/widget-configurator.tsx`)

- Admin interface for widget customization
- Live preview of widget appearance
- Multiple embed code generation options:
  - Standard script embed
  - Google Tag Manager integration
  - Direct body embed
- Configuration persistence in Supabase

#### Widget Script (`public/widget/chat-widget.js`)

- Minified, self-initializing script
- No external dependencies required
- Cross-domain communication handling
- Error resilience with graceful degradation
- Customization via configuration object

### 7. Authentication System

A robust authentication system using Supabase Auth with JWT-based session handling.

#### Authentication Flow

1. **Token Refresh**: Implemented in root middleware to ensure valid sessions
2. **Route Protection**: Checks user authentication and role-based permissions
3. **API Authentication**: Validates requests via auth headers
4. **Admin Verification**: Special checks for admin-only routes and actions

#### JWT Implementation

- Short-lived JWT tokens (1 hour)
- Automatic refresh via middleware
- Secure cookie storage with HTTP-only flags
- Role-based claims for permission management
- Database sync for user access control

### 8. Database Design

The database is built on Supabase PostgreSQL with specialized extensions and optimized schemas.

#### Key Tables

1. **profiles**: User profile information with business context
   ```sql
   CREATE TABLE public.profiles (
     id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
     full_name TEXT,
     company_name TEXT,
     company_description TEXT,
     company_location TEXT,
     website_url TEXT,
     website_summary TEXT,
     created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     is_admin BOOLEAN DEFAULT FALSE,
     metadata JSONB DEFAULT '{}'::JSONB
   );
   ```

2. **conversations**: Conversation metadata and tracking
   ```sql
   CREATE TABLE public.conversations (
     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
     user_id UUID REFERENCES public.profiles(id) ON DELETE CASCADE,
     title TEXT,
     created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     last_message_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     metadata JSONB DEFAULT '{}'::JSONB
   );
   ```

3. **messages**: Individual message storage with vector embeddings
   ```sql
   CREATE TABLE public.messages (
     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
     conversation_id UUID REFERENCES public.conversations(id) ON DELETE CASCADE,
     role TEXT NOT NULL,
     content TEXT NOT NULL,
     created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     embedding VECTOR(1536),
     metadata JSONB DEFAULT '{}'::JSONB
   );
   ```

4. **documents**: Knowledge base document storage
   ```sql
   CREATE TABLE public.documents (
     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
     title TEXT,
     content TEXT NOT NULL,
     source TEXT,
     created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
     metadata JSONB DEFAULT '{}'::JSONB
   );
   ```

5. **document_sections**: Chunked document sections with embeddings
   ```sql
   CREATE TABLE public.document_sections (
     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
     document_id UUID REFERENCES public.documents(id) ON DELETE CASCADE,
     content TEXT NOT NULL,
     embedding VECTOR(1536) NOT NULL,
     metadata JSONB DEFAULT '{}'::JSONB
   );
   ```

### 9. Rate Limiting Implementation

A multi-tier rate limiting system to protect the application from abuse.

#### Rate Limiting Tiers

1. **Standard API Routes**: 120 requests per minute
2. **AI-Related Endpoints**: 40 requests per minute
3. **Auth Endpoints**: 15 requests per minute
4. **History Endpoint**: 10 requests per minute
5. **Widget API**: 3 requests per minute

#### Implementation (`lib/middleware/rate-limit.ts`)

- Redis-based distributed rate limiter
- IP-based and user-based rate limiting
- Fallback to in-memory rate limiting if Redis is unavailable
- Custom headers for limit information
- Graduated response codes (429) with retry-after headers

### 10. Logging System

A comprehensive structured logging system for monitoring and debugging.

#### Logger Implementation (`lib/logger/index.ts`)

- Environment-aware logging levels
- Structured JSON format for machine readability
- Context preservation across async operations
- Performance metrics collection
- Error tracking with stack traces
- Client-side error reporting

#### Edge Logger (`lib/logger/edge-logger.ts`)

- Optimized for Edge runtime environments
- Minimal overhead for serverless functions
- Compatible with Vercel's logging infrastructure
- Sampling for high-volume endpoints
- Custom log severity levels

## Deployment Architecture

Marlan is deployed as a serverless application on Vercel, with the following components:

1. **Edge Functions**: For authentication middleware and API routes
2. **Serverless Functions**: For compute-intensive operations
3. **Static Assets**: For UI components and widget scripts
4. **Supabase Database**: For data storage and vector search
5. **Redis Cache**: For rate limiting and performance optimization

### Environment Variables

```
# Required
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
OPENAI_API_KEY=your_openai_api_key
NEXT_PUBLIC_APP_URL=https://your-app-url.vercel.app

# Optional
PERPLEXITY_API_KEY=your_perplexity_api_key
REDIS_URL=your_redis_url
REDIS_TOKEN=your_redis_token
LOG_LEVEL=info
WIDGET_ALLOWED_ORIGINS=https://example.com,*
NEXT_PUBLIC_MAX_TOKENS=600
```

## Key User Flows

### User Onboarding
1. User signs up via email authentication
2. Upon first login, user is redirected to profile setup page
3. User completes profile with business details (full name, company name, description, location)
4. Website URL can be provided for automatic content scraping and summary generation
5. System processes website in background and generates a concise business summary
6. Once profile is complete, user is directed to the chat interface
7. Profile information is automatically included in all future AI interactions

### Chat Interaction
1. User selects agent type (or uses auto-detection)
2. User sends a message query
3. System analyzes query using keyword scoring to determine appropriate specialized agent
4. If URLs are detected, content is automatically scraped and processed
5. If Deep Search is enabled, Perplexity API is called with progress tracking
6. Results from knowledge sources are prioritized (RAG → Web Scraping → Deep Search)
7. AI generates a streaming response with reference to tools used
8. Conversation is saved to history for future context and continuity

### Widget Integration
1. Admin configures widget appearance and behavior in admin dashboard
2. Admin copies embed code in preferred format (standard, GTM, or direct)
3. Widget code is placed on external website
4. Widget initializes and connects to the API endpoint
5. User interactions with widget use the same RAG and agent system
6. Conversations are rate-limited to prevent abuse

## Performance Optimization Techniques

1. **Vector Search Caching**: Cached vector search results reduce database load
2. **Embedding Caching**: Reduced OpenAI API calls for common embeddings
3. **Web Content Caching**: Cached web page content for frequently visited URLs
4. **Redis-Based Rate Limiting**: Distributed rate limiting for API protection
5. **Edge Middleware**: Fast token validation without database calls
6. **Streaming Responses**: Immediate response start with progressive rendering
7. **Optimized Token Usage**: Context window management for maximum efficiency
8. **Conditional Tool Execution**: Tools only run when needed to reduce latency

## Getting Started

### Prerequisites

- Node.js 18+ and npm
- Supabase account with vector extension enabled
- OpenAI API key
- Perplexity API key (optional, for deep search)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/marlan.git
   cd marlan
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Set up environment variables:
   ```bash
   cp .env.example .env.local
   # Edit .env.local with your values
   ```

4. Set up Supabase:
   - Create a new Supabase project
   - Enable the pgvector extension: `CREATE EXTENSION vector;`
   - Run the SQL from `supabase/migrations` in the Supabase SQL editor
   - Add your Supabase URL and anon key to `.env.local`

5. Run the development server:
   ```bash
   npm run dev
   ```

6. Open [http://localhost:3000](http://localhost:3000) in your browser.

### Deployment

1. Push your code to GitHub
2. Create a project on Vercel
3. Configure environment variables in Vercel
4. Deploy the application

## Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details. 