# Chat System Refactoring Plan

## Current Architecture Analysis

### Main Chat System
- **API Endpoint**: `app/api/chat/route.ts` (58KB)
- **Frontend**: Multiple components in `/components`
- **Features**: Full agent system, DeepSearch, history, specialized agents
- **Interface**: Rich UI with multiple tools and customizations 

### Widget Chat System
- **API Endpoint**: `app/api/widget-chat/route.ts` (16KB)
- **Frontend**: Lightweight components in `/components/chat-widget`
- **Features**: Simplified RAG with single agent, no authentication
- **Interface**: Embeddable, mobile-friendly widget

### Shared Components (Already Refactored)
- Vector search functionality (`lib/vector/documentRetrieval.ts`)
- Logging system (`lib/logger`)
- Web scraping utilities (`lib/agents/tools/web-scraper-tool.ts`)
- Document formatting utilities (`lib/vector/formatters.ts`)

## The Core Problem

Both chat implementations duplicate the process of:
1. Receiving an HTTP request
2. Validating input
3. Setting up the AI model and parameters
4. Defining or selecting AI tools
5. Calling the AI SDK (`streamText`)
6. Handling streaming responses
7. Interacting with caching (Redis)
8. Saving and managing messages

This duplication creates maintenance challenges and potential inconsistencies when making changes to core functionality.

## Refactoring Goals

1. **Create a unified chat engine** that serves both implementations
2. **Maintain distinct interfaces** for full chat vs. widget
3. **Reduce code duplication** while preserving separate feature sets
4. **Improve maintainability** with clearer separation of concerns
5. **Enable feature sharing** without forcing all features into both systems
6. **Centralize caching logic** for consistent implementation

## Refactoring Strategy

### Phase 1: Core Chat Engine Extraction

Create a modular chat engine that can be configured for different use cases:

```
lib/
  chat-engine/
    core.ts            # Shared chat processing logic
    prompts.ts         # Centralized prompt templates
    context-builder.ts # Logic for combining different context sources
    streaming.ts       # Shared streaming response utilities
    error-handling.ts  # Standardized error handling
    rate-limiting.ts   # Unified rate limiting approach
```

The core chat engine will:
- Accept configuration options to customize behavior for different implementations
- Handle the complete workflow from request validation to response streaming
- Support different authentication requirements
- Provide consistent error handling patterns

### Phase 2: Tool Registration System

Create a unified tool registration system that allows selective tool inclusion:

```
lib/
  chat-engine/
    tools/
      registry.ts       # Tool registration and management
      tool-factory.ts   # Factory for creating tools with consistent patterns
      knowledge-base.ts # Knowledge base tool implementation (RAG)
      web-scraper.ts    # Web scraper tool implementation
      deep-search.ts    # Deep search tool implementation
```

The tool system will:
- Define tools in a single location to avoid duplication
- Allow selective inclusion of tools for different implementations
- Maintain consistent error handling and logging patterns
- Support different tool configurations based on requirements

### Phase 3: Cache Service Creation

Create a centralized caching service:

```
lib/
  services/
    cache.service.ts   # Centralized Redis interaction
```

The cache service will:
- Handle all direct Redis interactions
- Provide consistent key management
- Handle serialization/deserialization consistently
- Standardize logging for cache operations
- Support different cache configurations

### Phase 4: Route Handler Refactoring

Refactor both route handlers to use the shared engine with different configurations:

```javascript
// app/api/chat/route.ts
import { createChatEngine } from '@/lib/chat-engine/core';
import { fullChatTools } from '@/lib/chat-engine/tools/registry';
import { prompts } from '@/lib/chat-engine/prompts';

export async function POST(req: Request) {
  const engine = createChatEngine({
    tools: fullChatTools,
    requiresAuth: true,
    systemPrompt: prompts.mainChat,
    maxTokens: 4096,
    // Additional full chat configuration
  });
  
  return engine.handleRequest(req);
}

// app/api/widget-chat/route.ts
import { createChatEngine } from '@/lib/chat-engine/core';
import { widgetTools } from '@/lib/chat-engine/tools/registry';
import { prompts } from '@/lib/chat-engine/prompts';

export async function POST(req: NextRequest) {
  const engine = createChatEngine({
    tools: widgetTools,
    requiresAuth: false,
    corsEnabled: true,
    systemPrompt: prompts.widgetChat,
    maxTokens: 2048,
    // Additional widget configuration
  });
  
  return engine.handleRequest(req);
}
```

### Phase 5: Frontend Component Adaptation

Maintain separate frontend components while sharing common logic:

```
components/
  shared/
    message-renderer.tsx   # Shared message rendering
    streaming-handler.tsx  # Shared streaming logic
  chat/                    # Full chat components
    [existing files]
  chat-widget/             # Widget-specific components
    [existing files]
```

## Implementation Progress

### Completed Tasks

#### Core Engine Creation (Step 1 - Completed)
- ✅ Created `lib/chat-engine/core.ts` with chat engine class and factory function
- ✅ Implemented auth handling, CORS configuration, and timeout management
- ✅ Added comprehensive logging and error handling

#### Prompt Management (Step 1 - Completed)
- ✅ Created `lib/chat-engine/prompts.ts` to centralize prompt management
- ✅ Reused existing agent prompt system (`lib/agents/prompts`) to avoid duplication
- ✅ Added specialized widget prompts for embedded experiences

#### Tool System (Step 2 - Completed)
- ✅ Created `lib/chat-engine/tools/knowledge-base.ts` with RAG functionality
- ✅ Created `lib/chat-engine/tools/web-scraper.ts` following Vercel AI SDK tool pattern
- ✅ Created `lib/chat-engine/tools/rag-tool.ts` for optimized RAG with Vercel AI SDK pattern
- ✅ Implemented `lib/chat-engine/tools/registry.ts` for tool management
- ✅ Created standardized tool sets for different implementations
- ✅ Updated core to use Vercel AI SDK's recommended tool-based context approach

#### Cache Service Creation (Step 3 - Completed)
- ✅ Created `lib/chat-engine/cache-service.ts` with centralized Redis caching
- ✅ Implemented consistent key generation and namespacing
- ✅ Added specialized methods for various data types (sessions, embeddings, context)
- ✅ Integrated with existing Redis client while abstracting implementation details
- ✅ Added proper error handling and logging for all cache operations
- ✅ Confirmed alignment with Redis best practices from redis-caching.md

#### Route Handler Refactoring (Step 4 - Completed)
- ✅ Refactored main chat route handler to use the new engine
- ✅ Refactored widget chat route handler to use the new engine
- ✅ Created agent routing model using the chat engine
- ✅ Added examples for all route handler implementations

#### Code Improvements (Step 5 - Completed)
- ✅ Extracted message history logic to `lib/chat-engine/message-history.ts`
- ✅ Improved separation of concerns in core.ts
- ✅ Simplified the ChatEngine class by delegating history management
- ✅ Added MessageHistoryService with enhanced functionality

### Current Task (Completed)

#### Agent Routing Implementation (Step 6 - Completed)
- ✅ Created `lib/chat-engine/agent-router.ts` to implement AI-powered agent detection
- ✅ Implemented Vercel AI SDK's `generateObject` pattern with Zod schema
- ✅ Used direct mapping from agent type to configuration
- ✅ Created `app/api/agent-chat/route.ts` endpoint that follows the Vercel routing pattern
- ✅ Simplified implementation to match Vercel documentation exactly
- ✅ Made chat engine fully self-contained by moving prompt system directly into the chat engine module
- ✅ Removed dependency on old AgentRouter class for getting system prompts
- ✅ Implemented a modular file structure for prompts in `lib/chat-engine/prompts/` directory
- ✅ Added widget prompt support for embedded chat experiences
- ✅ Enhanced `streamText` implementation with callbacks following Vercel AI SDK best practices
- ✅ Added improved logging for tool calls and completion metrics using `onChunk` and `onFinish` callbacks

### Next Tasks

1. **Frontend Component Adaptation** (Step 7 - Completed)
   - ✅ Created `useAppChat` hook to wrap Vercel AI SDK's `useChat` with app-specific functionality
   - ✅ Implemented `chat-widget-v2.tsx` using the Vercel AI SDK pattern through `useAppChat`
   - ✅ Created a new standalone JS widget file `chat-widget-v2.js` for embedding on external sites
   - ✅ Updated embed snippet generator to use the new widget implementation
   - ✅ Updated main chat component to work with new response format
   - ✅ Updated admin widget page to use the new `ChatWidgetV2` component
   - ✅ Ensured the widget works on external websites (thehighrollersclub.io and marlan.photographytoprofits.com)
   - ✅ Created a symbolic link from `chat-widget.js` to `chat-widget-v2.js` for backward compatibility
   - ✅ Updated the widget configurator to work with the new widget implementation

2. **Testing and Validation** (Continuous)
   - Test engine with different configurations
   - Verify compatibility with existing implementations
   - Benchmark performance and token usage
   - Validate Redis cache effectiveness with key metrics

#### Widget Chat Components
- ✅ Replaced `components/chat-widget/chat-widget.tsx` with `chat-widget-v2.tsx` using the Vercel AI SDK through our custom `useAppChat` hook
- ✅ Removed dependency on `chat-widget-provider.tsx` by using Vercel AI SDK's state management
- ✅ Updated `index.tsx` to export the new `ChatWidgetV2` component
- ✅ Updated `embed-snippet.tsx` to generate embed code for the new implementation
- ✅ Created standalone widget JS file for embedding on external websites
- ✅ Maintained backward compatibility by replacing the old widget.js file with the new implementation
- ✅ Updated admin widget page to use the new `ChatWidgetV2` component
- ✅ Updated the `/app/widget.js/route.ts` file to redirect to the new widget implementation
- ✅ Deleted unnecessary map file and created a symbolic link for the widget.js file
- ✅ Ensured the widget works on external websites including thehighrollersclub.io and marlan.photographytoprofits.com

## Code Organization

The refactoring has resulted in a clean, modular codebase with clear separation of concerns:

```
lib/
  chat-engine/
    core.ts                   # Core chat engine with request handling
    message-history.ts        # Message history management service
    cache-service.ts          # Centralized Redis caching service
    agent-router.ts           # AI-powered agent detection and routing
    prompts/                  # Centralized prompt system
      index.ts                # Exports builder functions and types
      base-prompt.ts          # Base prompt shared by all agents
      copywriting-prompts.ts  # Copywriting agent specialized prompt
      google-ads-prompts.ts   # Google Ads agent specialized prompt
      facebook-ads-prompts.ts # Facebook Ads agent specialized prompt
      quiz-prompts.ts         # Quiz agent specialized prompt
      widget-prompt.ts        # Standard widget prompt
    tools/
      registry.ts             # Tool registration and management
      knowledge-base.ts       # Knowledge base tool implementation (RAG)
      web-scraper.ts          # Web scraper tool implementation
      rag-tool.ts             # RAG tool following Vercel AI SDK pattern
components/
  chat-widget/
    use-app-chat.ts           # Custom hook wrapping Vercel AI SDK's useChat
    chat-widget-v2.tsx        # Updated widget using Vercel AI SDK patterns
```

### Core Components

1. **ChatEngine** (core.ts)
   - Handles request processing, authentication, CORS
   - Orchestrates the interactions with tools and AI model
   - Delegates persistence to specialized services

2. **MessageHistoryService** (message-history.ts)
   - Manages loading and saving of conversation history
   - Provides conversation context for AI continuity
   - Handles session management and message limiting

3. **ChatEngineCache** (cache-service.ts)
   - Provides a centralized caching interface
   - Implements proper Redis key management
   - Offers specialized methods for various data types

4. **Prompt System** (prompts/index.ts and individual prompt files)
   - Centralizes all prompt definitions in separate files
   - Provides builder functions to compose complete prompts
   - Supports different agent types and chat experiences
   - Maintains clean separation between base and specialized instructions

5. **Tools Registry** (tools/registry.ts)
   - Centralizes tool registration
   - Provides flexible tool selection based on requirements
   - Ensures consistent tool implementation

## Route Handler Implementation

### Main Chat Route Handler Example

```typescript
// app/api/chat/route.ts
import { createChatEngine } from '@/lib/chat-engine/core';
import { fullChatTools } from '@/lib/chat-engine/tools/registry';
import { prompts } from '@/lib/chat-engine/prompts';

export const runtime = 'edge';

export async function POST(req: Request) {
  // Create a configured chat engine instance for the main chat
  const engine = createChatEngine({
    tools: fullChatTools,
    requiresAuth: true,
    systemPrompt: prompts.mainChat,
    maxTokens: 4096,
    temperature: 0.7,
    useDeepSearch: true,
    useWebScraper: true,
    operationName: 'main_chat',
    cacheEnabled: true,
    messageHistoryLimit: 50
  });
  
  // Let the engine handle the request
  return engine.handleRequest(req);
}
```

### Widget Chat Route Handler Example

```typescript
// app/api/widget-chat/route.ts
import { createChatEngine } from '@/lib/chat-engine/core';
import { widgetTools } from '@/lib/chat-engine/tools/registry';
import { prompts } from '@/lib/chat-engine/prompts';

export const runtime = 'edge';

export async function POST(req: Request) {
  // Create a configured chat engine instance for the widget chat
  const engine = createChatEngine({
    tools: widgetTools,
    requiresAuth: false,
    corsEnabled: true,
    systemPrompt: prompts.widgetChat,
    maxTokens: 2048,
    temperature: 0.7,
    useWebScraper: false,
    useDeepSearch: false,
    operationName: 'widget_chat',
    cacheEnabled: true,
    messageHistoryLimit: 20
  });
  
  // Let the engine handle the request
  return engine.handleRequest(req);
}
```

### Agent Routing Handler Example

```typescript
// app/api/agent-chat/route.ts
import { createChatEngine } from '@/lib/chat-engine/core';
import { createToolSet } from '@/lib/chat-engine/tools/registry';
import { detectAgentType } from '@/lib/agents/agent-detector';
import { prompts } from '@/lib/chat-engine/prompts';

export const runtime = 'edge';

export async function POST(req: Request) {
  const body = await req.json();
  const { message } = body;
  
  // Detect which specialized agent to use based on message content
  const agentType = await detectAgentType(message);
  
  // Select appropriate prompt and tools based on agent type
  const systemPrompt = prompts.getAgentPrompt(agentType);
  const tools = createToolSet({
    useKnowledgeBase: true,
    useWebScraper: agentType !== 'widget',
    useDeepSearch: agentType === 'copywriting' || agentType === 'ads',
    useRagTool: true
  });
  
  // Create a configured chat engine for the detected agent
  const engine = createChatEngine({
    tools,
    requiresAuth: true,
    systemPrompt,
    maxTokens: 4096,
    temperature: agentType === 'creative' ? 0.8 : 0.7,
    operationName: `agent_chat_${agentType}`,
    cacheEnabled: true
  });
  
  // Let the engine handle the request
  return engine.handleRequest(req);
}
```

## Agent Routing System

The agent routing system automatically selects the most appropriate specialized agent based on the user's message content. This is implemented through keyword-based scoring and contextual analysis.

### Agent Types

Our system supports the following specialized agents:

1. **Default Agent**: General marketing assistant for photographers
2. **Copywriting Agent**: Specialized in website, email, and marketing copy
3. **Google Ads Agent**: Expert in creating and optimizing Google Ads campaigns
4. **Facebook Ads Agent**: Focused on social media advertising strategies
5. **Quiz Agent**: Creates interactive quizzes and questionnaires for lead generation

### Routing Implementation

The agent detection system works through these key components:

1. **Keyword Dictionary**: 
   - Each agent type has an associated set of keywords with weights
   - Keywords closer to the beginning of a message get higher scores
   - Exact matches get higher scores than partial matches

2. **Contextual Analysis**:
   - Message length and structure affect scoring
   - Previous interactions in the conversation influence agent selection
   - Explicit requests for specific agent types override the scoring system

3. **Threshold-Based Selection**:
   - Scores must exceed minimum thresholds to trigger specialized agents
   - Default agent serves as fallback when no clear specialization is detected
   - Confidence scores determine when to suggest agent switching

### Integration with Chat Engine

The agent routing system is fully integrated with our chat engine architecture:

1. Agent detection happens at the route handler level
2. Selected agent determines which system prompt and tools to use
3. Chat engine configuration adapts based on agent requirements
4. All interactions are still processed through the unified chat engine

### Benefits of the New Architecture

1. **Unified Codebase**: All agents share the same core engine, reducing duplication
2. **Consistent UX**: Users get specialized help without manually switching agents
3. **Easy Extension**: Adding new agent types only requires updating the prompt and keyword dictionary
4. **Optimized Resource Usage**: Each agent only loads the tools it needs
5. **Better Context Management**: Agents can access shared context through the centralized cache

## Architecture Updates

### Tool-Based Context Approach

After reviewing the Vercel AI SDK documentation and examples, we've updated our approach to context handling. Instead of manually injecting context into prompts, we now follow the SDK's recommended tool-based pattern:

1. **RAG Tool**: Created a `rag-tool.ts` that leverages our vector search to retrieve relevant documents on demand when the AI needs context.

2. **Clean System Prompts**: The core engine now uses clean system prompts focused on behavior instructions, letting the AI decide when to retrieve context.

3. **Multi-Step Tool Execution**: Enabled `maxSteps: 5` to allow the AI to make multiple tool calls, gathering more context as needed.

Benefits of this approach:
- Reduced tokens (context retrieved only when needed)
- More dynamic interaction (AI can choose when to get more context)
- Better maintainability (each tool has a clear responsibility)
- Improved user experience (AI can explain what information it's using)

### Centralized Cache Service

The new cache service follows the patterns established in our Redis caching documentation:

1. **Consistent Key Management**:
   - Namespaced keys with prefixes for different data types
   - Type-safe interface with generics for retrieval
   - Organized TTL constants for different content types

2. **Robust Error Handling**:
   - All cache operations wrapped in try/catch blocks
   - Detailed logging with appropriate log levels
   - Graceful fallbacks when cache operations fail

3. **Environment Variables**:
   - Uses `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` for Redis connection
   - Fallback support for `KV_REST_API_URL` and `KV_REST_API_TOKEN` for backward compatibility

4. **Cache Data Structure Optimization**:
   - Specialized session storage for conversation history
   - JSON serialization handled automatically by Redis client
   - Type validation when retrieving cached data

5. **Performance Considerations**:
   - Appropriate TTL values for different data types
   - Limit on message history to control memory usage
   - Asynchronous cache updates to avoid blocking responses

### Message History Service

The new message history service enhances the conversation management:

1. **Clean Separation**:
   - Extracts message history logic from core.ts
   - Provides a dedicated service for conversation persistence
   - Reduces complexity in the ChatEngine class

2. **Enhanced Features**:
   - Adds getRecentHistory for optimized context retrieval
   - Provides addPlaceholderAndSave for streamlined saves
   - Automatically limits conversation history size

3. **Error Resilience**:
   - Includes comprehensive error handling
   - Gracefully falls back to basic functionality on failures
   - Prevents errors in history from affecting core functionality

## Migration Strategy

1. **Parallel Implementation**: Build new system alongside existing code
2. **Incremental Migration**: Migrate one component at a time, starting with lowest risk
3. **Feature Parity Testing**: Ensure each feature works identically before and after
4. **Fallback Mechanism**: Allow runtime fallback to original code during transition

## Expected Benefits

1. **Reduced Code Duplication**: Centralizing core chat logic will eliminate redundant code
2. **Improved Maintainability**: Changes to core functionality only need to happen in one place
3. **Consistent Error Handling**: Standardized approach to errors across implementations
4. **Simplified Feature Addition**: New features can be added to the core and selectively enabled
5. **Better Testing**: Core components can be tested in isolation with higher coverage
6. **Performance Optimization**: Improvements to core engine benefit all implementations
7. **Efficient Caching**: Centralized Redis caching reduces API calls and improves response times
8. **Intelligent Routing**: Users get specialized help without manually selecting agents
9. **Separation of Concerns**: Each service has a clear responsibility and focused APIs

## Risk Assessment and Mitigation

| Risk | Mitigation |
|------|------------|
| Feature Divergence | Clear configuration options to support different requirements |
| Performance Impact | Benchmark throughout development to catch regressions early |
| Error Handling | Design error handling to support different response formats |
| Migration Challenges | Implement incremental changes with thorough testing |

## Next Steps

1. **Continue Agent Routing Implementation**
   - Complete agent detection logic with keyword scoring
   - Implement specialized prompts for each agent type
   - Add agent-specific tool configurations

2. **Update Frontend Components**
   - Modify existing components to work with new response formats
   - Ensure proper tool result handling in UI
   - Update agent selection UI

3. **Implement Testing Strategy**
   - Add unit tests for core classes and services
   - Create integration tests for route handlers
   - Benchmark performance against legacy implementation

## Legacy Files to Replace

The following files will eventually be replaced by our new implementation once the refactoring is complete:

### Core Chat Logic Files

- `lib/chat/tools.ts` (8.8KB, 281 lines) - Will be replaced by tools registry and individual tool implementations
- `lib/chat/prompt-builder.ts` (19KB, 528 lines) - Will be replaced by modular prompts in separate files under lib/chat-engine/prompts/
- `lib/agents/agent-router.ts` - Will be replaced by the new agent-router.ts using Vercel AI SDK's generateObject pattern
- `lib/agents/prompts/*` - Will be gradually replaced by corresponding files in lib/chat-engine/prompts/
- `lib/chat/tool-manager.ts` (3.3KB, 123 lines) - Will be replaced by tools registry
- `lib/chat/tool-schemas.ts` (2.1KB, 71 lines) - Will be replaced by tool-specific schema definitions
- `lib/chat/response-validator.ts` (5.8KB, 170 lines) - Will be replaced by MessageHistoryService validation
- `lib/chat/response-transformer.ts` (2.9KB, 87 lines) - Will be replaced by stream processor in ChatEngine
- `lib/chat/validator.ts` (3.6KB, 114 lines) - Will be replaced by request validation in ChatEngine
- `lib/chat/stream-processor.ts` (4.7KB, 138 lines) - Will be replaced by Vercel AI SDK's native streaming

### API Route Files

- `app/api/chat/route.ts` (58KB, 1389 lines) - Will be replaced by refactored route using ChatEngine
- ✅ `app/api/widget-chat/route.ts` (16KB, 447 lines) - Replaced by refactored widget route using createChatEngine
- `app/api/chat/session/*` - Will be replaced by MessageHistoryService
- `app/api/chat/[id]/*` - Will be replaced by MessageHistoryService
- `app/api/chat/ai-message/*` - Will be replaced by MessageHistoryService and ChatEngine

### Utility Files to Keep or Modify

- `lib/chat/url-utils.ts` (2.6KB, 74 lines) - Consider keeping and using in the web scraper tool

### Frontend Components

The following frontend components will need to be updated to work with the new API routes and the Vercel AI SDK approach:

#### Main Chat Components
- `components/chat.tsx` - Will need updates to use Vercel AI SDK's `useChat` hook with the new route handlers
- `components/messages.tsx` - Will need updates for handling tool calls and multi-step execution
- `components/message.tsx` - Will need updates for displaying tool calls and results
- `components/message-actions.tsx` - May need updates for new message structure
- `components/multimodal-input.tsx` - For handling attachments with the new chat engine

#### Widget Chat Components
- ✅ Replaced `components/chat-widget/chat-widget.tsx` with `chat-widget-v2.tsx` using the Vercel AI SDK through our custom `useAppChat` hook
- ✅ Removed dependency on `chat-widget-provider.tsx` by using Vercel AI SDK's state management
- ✅ Updated `index.tsx` to export the new `ChatWidgetV2` component
- ✅ Updated `embed-snippet.tsx` to generate embed code for the new implementation
- ✅ Created standalone widget JS file for embedding on external websites
- ✅ Maintained backward compatibility by replacing the old widget.js file with the new implementation
- ✅ Updated admin widget page to use the new `ChatWidgetV2` component
- ✅ Updated the `/app/widget.js/route.ts` file to redirect to the new widget implementation
- ✅ Deleted unnecessary map file and created a symbolic link for the widget.js file

#### Support Components
- Any components that display or interact with tool results
- Agent selection UI components

These components will need updates to work with the Vercel AI SDK's `useChat` hook, but will need configuration updates to work with our new refactored API routes. The transition should be relatively smooth as the Vercel AI SDK maintains similar interfaces.

#### Cold Start Optimization

- ✅ Implemented multi-layered cold start mitigation following Vercel AI SDK best practices
- ✅ Added proactive API warming when widget loads on external sites
- ✅ Created warmup script (`public/widget/wakeup.js`) for periodic pinging
- ✅ Added automatic retry mechanism in the `useAppChat` hook for first message failures
- ✅ Enhanced error handling in streamText with proper callbacks
- ✅ Documented cold start optimization approach and best practices
- ✅ Updated widget API endpoint to handle legacy and Vercel AI SDK request formats
- ✅ Optimized for Edge Runtime to reduce cold start times